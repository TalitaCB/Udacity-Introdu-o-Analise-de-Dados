{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-Dimensional NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2342.5999999999999, 3239.9000000000001)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Subway ridership for 5 stations on 10 different days\n",
    "ridership = np.array([\n",
    "    [   0,    0,    2,    5,    0],\n",
    "    [1478, 3877, 3674, 2328, 2539],\n",
    "    [1613, 4088, 3991, 6461, 2691],\n",
    "    [1560, 3392, 3826, 4787, 2613],\n",
    "    [1608, 4802, 3932, 4477, 2705],\n",
    "    [1576, 3933, 3909, 4979, 2685],\n",
    "    [  95,  229,  255,  496,  201],\n",
    "    [   2,    0,    1,   27,    0],\n",
    "    [1438, 3785, 3589, 4174, 2215],\n",
    "    [1342, 4043, 4009, 4665, 3033]\n",
    "])\n",
    "\n",
    "# Change False to True for each block of code to see what it does    \n",
    "\n",
    "\n",
    "def mean_riders_for_max_station(ridership):\n",
    "    '''\n",
    "    Fill in this function to find the station with the maximum riders on the\n",
    "    first day, then return the mean riders per day for that station. Also\n",
    "    return the mean ridership overall for comparsion.\n",
    "    \n",
    "    Hint: NumPy's argmax() function might be useful:\n",
    "    http://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html\n",
    "    '''\n",
    "    max_column = np.argmax(ridership[0, :])\n",
    "    mean_for_max = np.mean(ridership[:, max_column])\n",
    "    overall_mean = np.mean(ridership)\n",
    "   \n",
    "    \n",
    "    return (overall_mean, mean_for_max)\n",
    "\n",
    "print mean_riders_for_max_station(ridership)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2328\n",
      "[[2328 2539]\n",
      " [6461 2691]]\n",
      "[1478 3877 3674 2328 2539]\n"
     ]
    }
   ],
   "source": [
    "# Accessing elements\n",
    "if True:\n",
    "    print ridership[1, 3]\n",
    "    print ridership[1:3, 3:5]\n",
    "    print ridership[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1478 3877 3676 2333 2539]\n",
      "[   0 5355 5701 4952 6410 5509  324    2 5223 5385]\n"
     ]
    }
   ],
   "source": [
    "# Vectorized operations on rows or columns\n",
    "if True:\n",
    "    print ridership[0, :] + ridership[1, :]\n",
    "    print ridership[:, 0] + ridership[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  3  4]\n",
      " [ 6  7  8]\n",
      " [10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "# Vectorized operations on entire arrays\n",
    "if True:\n",
    "    a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "    b = np.array([[1, 1, 1], [2, 2, 2], [3, 3, 3]])\n",
    "    print a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3239.9000000000001, 1071.2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def min_and_max_riders_per_day(ridership):\n",
    "    '''\n",
    "    Fill in this function. First, for each subway station, calculate the\n",
    "    mean ridership per day. Then, out of all the subway stations, return the\n",
    "    maximum and minimum of these values. That is, find the maximum\n",
    "    mean-ridership-per-day and the minimum mean-ridership-per-day for any\n",
    "    subway station.\n",
    "    '''\n",
    "    \n",
    "    station_mean = np.mean(ridership, axis=0)\n",
    "    \n",
    "    max_daily_ridership = np.amax(station_mean)\n",
    "    min_daily_ridership = np.amin(station_mean)    \n",
    "    \n",
    "    return (max_daily_ridership, min_daily_ridership)\n",
    "\n",
    "min_and_max_riders_per_day(ridership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1071.2,  2814.9,  2718.8,  3239.9,  1868.2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ridership, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Elements of a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2342.5999999999999, 3239.9)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Subway ridership for 5 stations on 10 different days\n",
    "ridership_df = pd.DataFrame(\n",
    "    data=[[   0,    0,    2,    5,    0],\n",
    "          [1478, 3877, 3674, 2328, 2539],\n",
    "          [1613, 4088, 3991, 6461, 2691],\n",
    "          [1560, 3392, 3826, 4787, 2613],\n",
    "          [1608, 4802, 3932, 4477, 2705],\n",
    "          [1576, 3933, 3909, 4979, 2685],\n",
    "          [  95,  229,  255,  496,  201],\n",
    "          [   2,    0,    1,   27,    0],\n",
    "          [1438, 3785, 3589, 4174, 2215],\n",
    "          [1342, 4043, 4009, 4665, 3033]],\n",
    "    index=['05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11',\n",
    "           '05-06-11', '05-07-11', '05-08-11', '05-09-11', '05-10-11'],\n",
    "    columns=['R003', 'R004', 'R005', 'R006', 'R007']\n",
    ")\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "def mean_riders_for_max_station(ridership):\n",
    "    '''\n",
    "    Fill in this function to find the station with the maximum riders on the\n",
    "    first day, then return the mean riders per day for that station. Also\n",
    "    return the mean ridership overall for comparsion.\n",
    "    \n",
    "    This is the same as a previous exercise, but this time the\n",
    "    input is a Pandas DataFrame rather than a 2D NumPy array.\n",
    "    '''\n",
    "    \n",
    "    max_column = ridership.iloc[0].argmax()\n",
    "    mean_for_max = ridership[max_column].mean()\n",
    "    overall_mean = ridership.values.mean()\n",
    "    \n",
    "    return (overall_mean, mean_for_max)\n",
    "\n",
    "mean_riders_for_max_station(ridership_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  0  3\n",
      "1  1  4\n",
      "2  2  5\n",
      "   A  B  C\n",
      "0  0  1  2\n",
      "1  3  4  5\n"
     ]
    }
   ],
   "source": [
    "# DataFrame creation\n",
    "if True:\n",
    "    # You can create a DataFrame out of a dictionary mapping column names to values\n",
    "    df_1 = pd.DataFrame({'A': [0, 1, 2], 'B': [3, 4, 5]})\n",
    "    print df_1\n",
    "\n",
    "    # You can also use a list of lists or a 2D NumPy array\n",
    "    df_2 = pd.DataFrame([[0, 1, 2], [3, 4, 5]], columns=['A', 'B', 'C'])\n",
    "    print df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R003    0\n",
      "R004    0\n",
      "R005    2\n",
      "R006    5\n",
      "R007    0\n",
      "Name: 05-01-11, dtype: int64\n",
      "R003    1608\n",
      "R004    4802\n",
      "R005    3932\n",
      "R006    4477\n",
      "R007    2705\n",
      "Name: 05-05-11, dtype: int64\n",
      "05-01-11       0\n",
      "05-02-11    1478\n",
      "05-03-11    1613\n",
      "05-04-11    1560\n",
      "05-05-11    1608\n",
      "05-06-11    1576\n",
      "05-07-11      95\n",
      "05-08-11       2\n",
      "05-09-11    1438\n",
      "05-10-11    1342\n",
      "Name: R003, dtype: int64\n",
      "2328\n"
     ]
    }
   ],
   "source": [
    "# Accessing elements\n",
    "if True:\n",
    "    print ridership_df.iloc[0]\n",
    "    print ridership_df.loc['05-05-11']\n",
    "    print ridership_df['R003']\n",
    "    print ridership_df.iloc[1, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          R003  R004  R005  R006  R007\n",
      "05-02-11  1478  3877  3674  2328  2539\n",
      "05-03-11  1613  4088  3991  6461  2691\n",
      "05-04-11  1560  3392  3826  4787  2613\n"
     ]
    }
   ],
   "source": [
    "# Accessing multiple rows\n",
    "if True:\n",
    "    print ridership_df.iloc[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          R003  R005\n",
      "05-01-11     0     2\n",
      "05-02-11  1478  3674\n",
      "05-03-11  1613  3991\n",
      "05-04-11  1560  3826\n",
      "05-05-11  1608  3932\n",
      "05-06-11  1576  3909\n",
      "05-07-11    95   255\n",
      "05-08-11     2     1\n",
      "05-09-11  1438  3589\n",
      "05-10-11  1342  4009\n"
     ]
    }
   ],
   "source": [
    "# Accessing multiple columns\n",
    "if True:\n",
    "    print ridership_df[['R003', 'R005']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A     3\n",
      "B    12\n",
      "dtype: int64\n",
      "0    3\n",
      "1    5\n",
      "2    7\n",
      "dtype: int64\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# Pandas axis\n",
    "if True:\n",
    "    df = pd.DataFrame({'A': [0, 1, 2], 'B': [3, 4, 5]})\n",
    "    print df.sum()\n",
    "    print df.sum(axis=1)\n",
    "    print df.values.sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = '/datasets/ud170/subway/nyc_subway_weather.csv'\n",
    "subway_df = pd.read_csv(filename)\n",
    "\n",
    "def correlation(x, y):\n",
    "    '''\n",
    "    Fill in this function to compute the correlation between the two\n",
    "    input variables. Each input is either a NumPy array or a Pandas\n",
    "    Series.\n",
    "    \n",
    "    correlation = average of (x in standard units) times (y in standard units)\n",
    "    \n",
    "    Remember to pass the argument \"ddof=0\" to the Pandas std() function!\n",
    "    '''\n",
    "    \n",
    "    stand_x = (x - x.mean()) / x.std(ddof=0)\n",
    "    stand_y = (y - y.mean()) / y.std(ddof=0)\n",
    "    prod = (stand_x * stand_y)\n",
    "    correl = prod.mean()\n",
    "    \n",
    "    \n",
    "    return correl\n",
    "\n",
    "entries = subway_df['ENTRIESn_hourly']\n",
    "cum_entries = subway_df['ENTRIESn']\n",
    "rain = subway_df['meanprecipi']\n",
    "temp = subway_df['meantempi']\n",
    "\n",
    "print correlation(entries, rain)\n",
    "print correlation(entries, temp)\n",
    "print correlation(rain, temp)\n",
    "\n",
    "print correlation(entries, cum_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame Vectorized Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ENTRIESn  EXITSn\n",
      "0       NaN     NaN\n",
      "1      23.0     8.0\n",
      "2      18.0    18.0\n",
      "3      71.0    54.0\n",
      "4     170.0    44.0\n",
      "5     214.0    42.0\n",
      "6      87.0    11.0\n",
      "7      10.0     3.0\n",
      "8      36.0    89.0\n",
      "9     153.0   333.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cumulative entries and exits for one station for a few hours\n",
    "entries_and_exits = pd.DataFrame({\n",
    "    'ENTRIESn': [3144312, 3144335, 3144353, 3144424, 3144594,\n",
    "                 3144808, 3144895, 3144905, 3144941, 3145094],\n",
    "    'EXITSn': [1088151, 1088159, 1088177, 1088231, 1088275,\n",
    "               1088317, 1088328, 1088331, 1088420, 1088753]\n",
    "})\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "    \n",
    "def get_hourly_entries_and_exits(entries_and_exits):\n",
    "    '''\n",
    "    Fill in this function to take a DataFrame with cumulative entries\n",
    "    and exits (entries in the first column, exits in the second) and\n",
    "    return a DataFrame with hourly entries and exits (entries in the\n",
    "    first column, exits in the second).\n",
    "    '''\n",
    "   \n",
    "    return entries_and_exits - entries_and_exits.shift(1)\n",
    "\n",
    "print get_hourly_entries_and_exits(entries_and_exits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENTRIESn</th>\n",
       "      <th>EXITSn</th>\n",
       "      <th>DiffEntries</th>\n",
       "      <th>DiffEXITSn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3144312</td>\n",
       "      <td>1088151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3144335</td>\n",
       "      <td>1088159</td>\n",
       "      <td>3144312.0</td>\n",
       "      <td>1088151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3144353</td>\n",
       "      <td>1088177</td>\n",
       "      <td>3144335.0</td>\n",
       "      <td>1088159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3144424</td>\n",
       "      <td>1088231</td>\n",
       "      <td>3144353.0</td>\n",
       "      <td>1088177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3144594</td>\n",
       "      <td>1088275</td>\n",
       "      <td>3144424.0</td>\n",
       "      <td>1088231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3144808</td>\n",
       "      <td>1088317</td>\n",
       "      <td>3144594.0</td>\n",
       "      <td>1088275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3144895</td>\n",
       "      <td>1088328</td>\n",
       "      <td>3144808.0</td>\n",
       "      <td>1088317.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3144905</td>\n",
       "      <td>1088331</td>\n",
       "      <td>3144895.0</td>\n",
       "      <td>1088328.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3144941</td>\n",
       "      <td>1088420</td>\n",
       "      <td>3144905.0</td>\n",
       "      <td>1088331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3145094</td>\n",
       "      <td>1088753</td>\n",
       "      <td>3144941.0</td>\n",
       "      <td>1088420.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENTRIESn   EXITSn  DiffEntries  DiffEXITSn\n",
       "0   3144312  1088151          NaN         NaN\n",
       "1   3144335  1088159    3144312.0   1088151.0\n",
       "2   3144353  1088177    3144335.0   1088159.0\n",
       "3   3144424  1088231    3144353.0   1088177.0\n",
       "4   3144594  1088275    3144424.0   1088231.0\n",
       "5   3144808  1088317    3144594.0   1088275.0\n",
       "6   3144895  1088328    3144808.0   1088317.0\n",
       "7   3144905  1088331    3144895.0   1088328.0\n",
       "8   3144941  1088420    3144905.0   1088331.0\n",
       "9   3145094  1088753    3144941.0   1088420.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries_and_exits['DiffEntries'] = entries_and_exits['ENTRIESn'].shift(1)\n",
    "entries_and_exits['DiffEXITSn'] = entries_and_exits['EXITSn'].shift(1)\n",
    "entries_and_exits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding DataFrames with the column names\n",
    "if True:\n",
    "    df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})\n",
    "    df2 = pd.DataFrame({'a': [10, 20, 30], 'b': [40, 50, 60], 'c': [70, 80, 90]})\n",
    "    print df1 + df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c   d\n",
      "0 NaN  74  47 NaN\n",
      "1 NaN  85  58 NaN\n",
      "2 NaN  96  69 NaN\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})\n",
    "    df2 = pd.DataFrame({'d': [10, 20, 30], 'c': [40, 50, 60], 'b': [70, 80, 90]})\n",
    "    print df1 + df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         a     b     c\n",
      "row1   NaN   NaN   NaN\n",
      "row2  32.0  65.0  98.0\n",
      "row3  23.0  56.0  89.0\n",
      "row4   NaN   NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]},\n",
    "                       index=['row1', 'row2', 'row3'])\n",
    "    df2 = pd.DataFrame({'a': [10, 20, 30], 'b': [40, 50, 60], 'c': [70, 80, 90]},\n",
    "                       index=['row4', 'row3', 'row2'])\n",
    "    print df1 + df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# DataFrame applymap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam1</th>\n",
       "      <th>exam2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Andre</th>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barry</th>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chris</th>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dan</th>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emilio</th>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fred</th>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greta</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humbert</th>\n",
       "      <td>D</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ivan</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        exam1 exam2\n",
       "Andre       F     F\n",
       "Barry       B     D\n",
       "Chris       C     F\n",
       "Dan         C     F\n",
       "Emilio      B     D\n",
       "Fred        C     F\n",
       "Greta       A     C\n",
       "Humbert     D     F\n",
       "Ivan        A     C\n",
       "James       B     D"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "\n",
    "    \n",
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "    \n",
    "def convert_grade(grade):\n",
    "    '''\n",
    "    Fill in this function to convert the given DataFrame of numerical\n",
    "    grades to letter grades. Return a new DataFrame with the converted\n",
    "    grade.\n",
    "    \n",
    "    The conversion rule is:\n",
    "        90-100 -> A\n",
    "        80-89  -> B\n",
    "        70-79  -> C\n",
    "        60-69  -> D\n",
    "        0-59   -> F\n",
    "    '''\n",
    "    nota = 'F'\n",
    "    if grade >= 60:\n",
    "        nota =  'D'\n",
    "        if grade >= 70:\n",
    "            nota = 'C'\n",
    "            if grade >= 80:\n",
    "                nota = 'B'\n",
    "                if grade >= 90:\n",
    "                    nota = 'A'\n",
    "                    \n",
    "\n",
    "    return nota\n",
    "    \n",
    "def convert_grades(grades):\n",
    "    \n",
    "     return grades.applymap(convert_grade)\n",
    "\n",
    "convert_grades(grades_df)\n",
    "#grades_df.applymap(convert_grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DataFrame applymap()\n",
    "if True:\n",
    "    df = pd.DataFrame({\n",
    "        'a': [1, 2, 3],\n",
    "        'b': [10, 20, 30],\n",
    "        'c': [5, 10, 15]\n",
    "    })\n",
    "    \n",
    "    def add_one(x):\n",
    "        return x + 1\n",
    "        \n",
    "    print df.applymap(add_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame applymap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andre      F\n",
      "Barry      B\n",
      "Chris      C\n",
      "Dan        C\n",
      "Emilio     B\n",
      "Fred       C\n",
      "Greta      A\n",
      "Humbert    D\n",
      "Ivan       A\n",
      "James      B\n",
      "Name: exam1, dtype: category\n",
      "Categories (5, object): [F < D < C < B < A]\n",
      "        exam1 exam2\n",
      "Andre       F     F\n",
      "Barry       B     B\n",
      "Chris       C     C\n",
      "Dan         C     C\n",
      "Emilio      B     B\n",
      "Fred        C     C\n",
      "Greta       A     A\n",
      "Humbert     D     D\n",
      "Ivan        A     A\n",
      "James       B     B\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# DataFrame apply()\n",
    "if True:\n",
    "    def convert_grades_curve(exam_grades):\n",
    "        # Pandas has a bult-in function that will perform this calculation\n",
    "        # This will give the bottom 0% to 10% of students the grade 'F',\n",
    "        # 10% to 20% the grade 'D', and so on. You can read more about\n",
    "        # the qcut() function here:\n",
    "        # http://pandas.pydata.org/pandas-docs/stable/generated/pandas.qcut.html\n",
    "        return pd.qcut(exam_grades,\n",
    "                       [0, 0.1, 0.2, 0.5, 0.8, 1],\n",
    "                       labels=['F', 'D', 'C', 'B', 'A'])\n",
    "        \n",
    "    # qcut() operates on a list, array, or Series. This is the\n",
    "    # result of running the function on a single column of the\n",
    "    # DataFrame.\n",
    "    print convert_grades_curve(grades_df['exam1'])\n",
    "    \n",
    "    # qcut() does not work on DataFrames, but we can use apply()\n",
    "    # to call the function on each column separately\n",
    "    print grades_df.apply(convert_grades_curve)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam1</th>\n",
       "      <th>exam2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Andre</th>\n",
       "      <td>-2.315341</td>\n",
       "      <td>-2.304599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barry</th>\n",
       "      <td>0.220191</td>\n",
       "      <td>0.386400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chris</th>\n",
       "      <td>0.020017</td>\n",
       "      <td>-0.096600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dan</th>\n",
       "      <td>-0.180156</td>\n",
       "      <td>-0.096600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emilio</th>\n",
       "      <td>0.753987</td>\n",
       "      <td>0.662400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fred</th>\n",
       "      <td>-0.513779</td>\n",
       "      <td>-0.441600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greta</th>\n",
       "      <td>0.887436</td>\n",
       "      <td>1.490400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humbert</th>\n",
       "      <td>-0.847401</td>\n",
       "      <td>-0.786600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ivan</th>\n",
       "      <td>1.354508</td>\n",
       "      <td>1.007400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>0.620538</td>\n",
       "      <td>0.179400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            exam1     exam2\n",
       "Andre   -2.315341 -2.304599\n",
       "Barry    0.220191  0.386400\n",
       "Chris    0.020017 -0.096600\n",
       "Dan     -0.180156 -0.096600\n",
       "Emilio   0.753987  0.662400\n",
       "Fred    -0.513779 -0.441600\n",
       "Greta    0.887436  1.490400\n",
       "Humbert -0.847401 -0.786600\n",
       "Ivan     1.354508  1.007400\n",
       "James    0.620538  0.179400"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "def standardize_column(coluna):\n",
    "    '''\n",
    "    Fill in this function to standardize each column of the given\n",
    "    DataFrame. To standardize a variable, convert each value to the\n",
    "    number of standard deviations it is above or below the mean.\n",
    "    '''\n",
    "    media = coluna.mean()\n",
    "    std = coluna.std(ddof=0)\n",
    "    \n",
    "    standar = (coluna - media) / std\n",
    "    \n",
    "    \n",
    "    \n",
    "    return standar\n",
    "\n",
    "def standardize(df):\n",
    "    return df.apply(standardize_column)\n",
    "\n",
    "#standardize(grades_df)\n",
    "\n",
    "grades_df.apply(standardize_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame apply() Use Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     4\n",
       "b    40\n",
       "c    20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'a': [4, 5, 3, 1, 2],\n",
    "    'b': [20, 10, 40, 50, 30],\n",
    "    'c': [25, 20, 5, 15, 10]\n",
    "})\n",
    "\n",
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# DataFrame apply() - use case 2\n",
    "if False:   \n",
    "    print df.apply(np.mean)\n",
    "    print df.apply(np.max)\n",
    "    \n",
    "def second_largest(df):\n",
    "    '''\n",
    "    Fill in this function to return the second-largest value of each \n",
    "    column of the input DataFrame.\n",
    "    '''\n",
    "   \n",
    "    \n",
    "    return df.apply(segunda_maior_coluna)\n",
    "\n",
    "#df.apply(second_largest)\n",
    "\n",
    "def segunda_maior_coluna(coluna):\n",
    "    \n",
    "    coluna_ordenada = coluna.sort_values(ascending=False)\n",
    "    \n",
    "    return coluna_ordenada.iloc[1]\n",
    "\n",
    "\n",
    "\n",
    "#second_largest(df)\n",
    "df.apply(segunda_maior_coluna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a DataFrame to a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1    2    3\n",
      "0  10  50   90  130\n",
      "1  20  60  100  140\n",
      "2  30  70  110  150\n",
      "3  40  80  120  160\n",
      "\n",
      "    0   1    2    3\n",
      "0  11  52   93  134\n",
      "1  21  62  103  144\n",
      "2  31  72  113  154\n",
      "3  41  82  123  164\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Adding a Series to a square DataFrame\n",
    "if True:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3\n",
      "0  10  20  30  40\n",
      "\n",
      "    0   1   2   3\n",
      "0  11  22  33  44\n"
     ]
    }
   ],
   "source": [
    "# Adding a Series to a one-row DataFrame \n",
    "if True:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({0: [10], 1: [20], 2: [30], 3: [40]})\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0\n",
      "0  10\n",
      "1  20\n",
      "2  30\n",
      "3  40\n",
      "\n",
      "    0   1   2   3\n",
      "0  11 NaN NaN NaN\n",
      "1  21 NaN NaN NaN\n",
      "2  31 NaN NaN NaN\n",
      "3  41 NaN NaN NaN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Adding a Series to a one-column DataFrame\n",
    "if True:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({0: [10, 20, 30, 40]})\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b    c    d\n",
      "0  10  50   90  130\n",
      "1  20  60  100  140\n",
      "2  30  70  110  150\n",
      "3  40  80  120  160\n",
      "\n",
      "    a   b    c    d\n",
      "0  11  52   93  134\n",
      "1  21  62  103  144\n",
      "2  31  72  113  154\n",
      "3  41  82  123  164\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "    \n",
    "# Adding when DataFrame column names match Series index\n",
    "if True:\n",
    "    s = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "    df = pd.DataFrame({\n",
    "        'a': [10, 20, 30, 40],\n",
    "        'b': [50, 60, 70, 80],\n",
    "        'c': [90, 100, 110, 120],\n",
    "        'd': [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b    c    d\n",
      "0  10  50   90  130\n",
      "1  20  60  100  140\n",
      "2  30  70  110  150\n",
      "3  40  80  120  160\n",
      "\n",
      "    0   1   2   3   a   b   c   d\n",
      "0 NaN NaN NaN NaN NaN NaN NaN NaN\n",
      "1 NaN NaN NaN NaN NaN NaN NaN NaN\n",
      "2 NaN NaN NaN NaN NaN NaN NaN NaN\n",
      "3 NaN NaN NaN NaN NaN NaN NaN NaN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Adding when DataFrame column names don't match Series index\n",
    "if True:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        'a': [10, 20, 30, 40],\n",
    "        'b': [50, 60, 70, 80],\n",
    "        'c': [90, 100, 110, 120],\n",
    "        'd': [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardizing Each Column Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam1</th>\n",
       "      <th>exam2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Andre</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barry</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chris</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dan</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emilio</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fred</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greta</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humbert</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ivan</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         exam1  exam2\n",
       "Andre      1.0   -1.0\n",
       "Barry      1.0   -1.0\n",
       "Chris      1.0   -1.0\n",
       "Dan        1.0   -1.0\n",
       "Emilio     1.0   -1.0\n",
       "Fred       1.0   -1.0\n",
       "Greta      1.0   -1.0\n",
       "Humbert    1.0   -1.0\n",
       "Ivan       1.0   -1.0\n",
       "James      1.0   -1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "\n",
    "def standardize(df):\n",
    "    '''\n",
    "    Fill in this function to standardize each column of the given\n",
    "    DataFrame. To standardize a variable, convert each value to the\n",
    "    number of standard deviations it is above or below the mean.\n",
    "    \n",
    "    This time, try to use vectorized operations instead of apply().\n",
    "    You should get the same results as you did before.\n",
    "    '''\n",
    "    \n",
    "    media = df.mean(axis=0)\n",
    "    std = df.std(axis = 0, ddof=0)\n",
    "    \n",
    "    standar = (df - media) / std\n",
    "    \n",
    "    \n",
    "    \n",
    "    return standar\n",
    "\n",
    "\n",
    "\n",
    "       \n",
    "def standardize_rows(df):\n",
    "    '''\n",
    "    Optional: Fill in this function to standardize each row of the given\n",
    "    DataFrame. Again, try not to use apply().\n",
    "    \n",
    "    This one is more challenging than standardizing each column!\n",
    "    '''\n",
    "    media_linha = df.mean(axis=1)\n",
    "    std_linhas = df.std(axis = 1, ddof=0)\n",
    "    \n",
    "    standar_linha_sub = df.subtract(media_linha, axis=0)\n",
    "    standar_linha = standar_linha_sub.div(std_linhas, axis=0)\n",
    "\n",
    "    return standar_linha\n",
    "\n",
    "#media = grades_df.mean(axis=0)\n",
    "#std = grades_df.std(axis = 0, ddof=0)\n",
    "    \n",
    "#standar = (grades_df - media) / std\n",
    "\n",
    "#standar\n",
    "\n",
    "\n",
    "#media_linha = grades_df.mean(axis=1)\n",
    "#std_linhas = grades_df.std(axis = 1, ddof=0)\n",
    "    \n",
    "#standar_linha_sub = grades_df.subtract(media_linha, axis=0)\n",
    "#standar_linha = standar_linha_sub.div(std_linhas, axis=0)\n",
    "\n",
    "#standar_linha\n",
    "standardize(grades_df)\n",
    "standardize_rows(grades_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1    2    3\n",
      "0  10  50   90  130\n",
      "1  20  60  100  140\n",
      "2  30  70  110  150\n",
      "3  40  80  120  160\n",
      "\n",
      "    0   1    2    3\n",
      "0  11  52   93  134\n",
      "1  21  62  103  144\n",
      "2  31  72  113  154\n",
      "3  41  82  123  164\n"
     ]
    }
   ],
   "source": [
    "# Adding using +\n",
    "if True:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1    2    3\n",
      "0  10  50   90  130\n",
      "1  20  60  100  140\n",
      "2  30  70  110  150\n",
      "3  40  80  120  160\n",
      "\n",
      "    0   1    2    3\n",
      "0  11  51   91  131\n",
      "1  22  62  102  142\n",
      "2  33  73  113  153\n",
      "3  44  84  124  164\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "# Adding with axis='index'\n",
    "if True:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df.add(s, axis='index')\n",
    "    # The functions sub(), mul(), and div() work similarly to add()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1    2    3\n",
      "0  10  50   90  130\n",
      "1  20  60  100  140\n",
      "2  30  70  110  150\n",
      "3  40  80  120  160\n",
      "\n",
      "    0   1    2    3\n",
      "0  11  52   93  134\n",
      "1  21  62  103  144\n",
      "2  31  72  113  154\n",
      "3  41  82  123  164\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "# Adding with axis='columns'\n",
    "if True:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df.add(s, axis='columns')\n",
    "    # The functions sub(), mul(), and div() work similarly to add()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rain       \n",
       "0     count    33064.000000\n",
       "      mean      1845.539439\n",
       "      std       2878.770848\n",
       "      min          0.000000\n",
       "      25%        269.000000\n",
       "      50%        893.000000\n",
       "      75%       2197.000000\n",
       "      max      32814.000000\n",
       "1     count     9585.000000\n",
       "      mean      2028.196035\n",
       "      std       3189.433373\n",
       "      min          0.000000\n",
       "      25%        295.000000\n",
       "      50%        939.000000\n",
       "      75%       2424.000000\n",
       "      max      32289.000000\n",
       "Name: ENTRIESn_hourly, dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "    \n",
    "filename = 'D:/Talita/Pessoal/Udacity/IAD/nyc_subway_weather.csv'\n",
    "\n",
    "subway_df = pd.read_csv(filename)\n",
    "\n",
    "### Write code here to group the subway data by a variable of your choice, then\n",
    "### either print out the mean ridership within each group or create a plot.a\n",
    "\n",
    "\n",
    "grouped_data = subway_df.groupby('rain')\n",
    "    \n",
    "\n",
    "grouped_data.describe()['ENTRIESn_hourly']\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  above_three   even  value\n",
      "a       False  False      1\n",
      "b       False  False      3\n",
      "c       False   True      2\n",
      "d        True   True      4\n",
      "e       False  False      1\n",
      "f        True   True      6\n",
      "g        True   True      4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Examine DataFrame\n",
    "if True:\n",
    "    print example_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.DataFrameGroupBy object at 0x000000000C130EB8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "# Examine groups\n",
    "#if True:\n",
    " #   grouped_data = \n",
    "    \n",
    "    # The groups attribute is a dictionary mapping keys to lists of row indexes\n",
    "#print grouped_data.groups\n",
    "    \n",
    "example_df.groupby('even')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(True, False): ['c'], (False, False): ['a', 'b', 'e'], (True, True): ['d', 'f', 'g']}\n"
     ]
    }
   ],
   "source": [
    "# Group by multiple columns\n",
    "if True:\n",
    "    grouped_data = example_df.groupby(['even', 'above_three'])\n",
    "    print grouped_data.groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.DataFrameGroupBy object at 0x000000000C1304A8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "# Get sum of each group\n",
    "#if True:\n",
    " #   grouped_data = \n",
    "#  print grouped_data.sum()\n",
    "    \n",
    "example_df.groupby('even')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "even\n",
      "False     5\n",
      "True     16\n",
      "Name: value, dtype: int32\n",
      "\n",
      "\n",
      "even\n",
      "False     5\n",
      "True     16\n",
      "Name: value, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# Limit columns in result\n",
    "if True:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    \n",
    "    # You can take one or more columns from the result DataFrame\n",
    "    print grouped_data.sum()['value']\n",
    "    \n",
    "    print '\\n' # Blank line to separate results\n",
    "    \n",
    "    # You can also take a subset of columns from the grouped data before \n",
    "    # collapsing to a DataFrame. In this case, the result is the same.\n",
    "    print grouped_data['value'].sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Hourly Entries and Exits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ENTRIESn  EXITSn\n",
      "0       NaN     NaN\n",
      "1       NaN     NaN\n",
      "2      23.0     8.0\n",
      "3      14.0     8.0\n",
      "4      18.0    18.0\n",
      "5      29.0   205.0\n",
      "6      71.0    54.0\n",
      "7     132.0   593.0\n",
      "8     170.0    44.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "ridership_df = pd.DataFrame({\n",
    "    'UNIT': ['R051', 'R079', 'R051', 'R079', 'R051', 'R079', 'R051', 'R079', 'R051'],\n",
    "    'TIMEn': ['00:00:00', '02:00:00', '04:00:00', '06:00:00', '08:00:00', '10:00:00', '12:00:00', '14:00:00', '16:00:00'],\n",
    "    'ENTRIESn': [3144312, 8936644, 3144335, 8936658, 3144353, 8936687, 3144424, 8936819, 3144594],\n",
    "    'EXITSn': [1088151, 13755385,  1088159, 13755393,  1088177, 13755598, 1088231, 13756191,  1088275]\n",
    "})\n",
    "\n",
    "def get_hourly_entries_and_exits(entries_and_exits):\n",
    "    '''\n",
    "    Fill in this function to take a DataFrame with cumulative entries\n",
    "    and exits and return a DataFrame with hourly entries and exits.\n",
    "    The hourly entries and exits should be calculated separately for\n",
    "    each station (the 'UNIT' column).\n",
    "    '''\n",
    "       \n",
    "    return entries_and_exits - entries_and_exits.shift(1)\n",
    "\n",
    "grouped_data = ridership_df.groupby('UNIT')\n",
    "    \n",
    "    \n",
    "print grouped_data['ENTRIESn','EXITSn'].apply(get_hourly_entries_and_exits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a   -0.577350\n",
      "b    1.154701\n",
      "c   -1.224745\n",
      "d    0.000000\n",
      "e   -0.577350\n",
      "f    1.224745\n",
      "g    0.000000\n",
      "Name: value, dtype: float64\n",
      "  above_three   even  value\n",
      "a       False  False      1\n",
      "b       False  False      3\n",
      "c       False   True      2\n",
      "d        True   True      4\n",
      "e       False  False      1\n",
      "f        True   True      6\n",
      "g        True   True      4\n"
     ]
    }
   ],
   "source": [
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Standardize each group\n",
    "if True:\n",
    "    def standardize(xs):\n",
    "        return (xs - xs.mean()) / xs.std()\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    print grouped_data['value'].apply(standardize)\n",
    "    \n",
    "print example_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "even\n",
      "False    1\n",
      "True     4\n",
      "Name: value, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find second largest value in each group\n",
    "if True:\n",
    "    def second_largest(xs):\n",
    "        sorted_xs = xs.sort_values(inplace=False, ascending=False)\n",
    "        return sorted_xs.iloc[1]\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    print grouped_data['value'].apply(second_largest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATEn</th>\n",
       "      <th>ENTRIESn</th>\n",
       "      <th>EXITSn</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>hour</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>fog</th>\n",
       "      <th>pressurei</th>\n",
       "      <th>rain</th>\n",
       "      <th>tempi</th>\n",
       "      <th>wspdi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05-01-11</td>\n",
       "      <td>4388333</td>\n",
       "      <td>2911002</td>\n",
       "      <td>R003</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>0</td>\n",
       "      <td>30.24</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-02-11</td>\n",
       "      <td>4388348</td>\n",
       "      <td>2911036</td>\n",
       "      <td>R003</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>0</td>\n",
       "      <td>30.32</td>\n",
       "      <td>0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05-03-11</td>\n",
       "      <td>4389885</td>\n",
       "      <td>2912127</td>\n",
       "      <td>R003</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>0</td>\n",
       "      <td>30.14</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05-04-11</td>\n",
       "      <td>4391507</td>\n",
       "      <td>2913223</td>\n",
       "      <td>R003</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>0</td>\n",
       "      <td>29.98</td>\n",
       "      <td>0</td>\n",
       "      <td>57.2</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05-05-11</td>\n",
       "      <td>4393043</td>\n",
       "      <td>2914284</td>\n",
       "      <td>R003</td>\n",
       "      <td>0</td>\n",
       "      <td>40.689945</td>\n",
       "      <td>-73.872564</td>\n",
       "      <td>0</td>\n",
       "      <td>30.01</td>\n",
       "      <td>0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>05-01-11</td>\n",
       "      <td>14656120</td>\n",
       "      <td>14451774</td>\n",
       "      <td>R004</td>\n",
       "      <td>0</td>\n",
       "      <td>40.691320</td>\n",
       "      <td>-73.867135</td>\n",
       "      <td>0</td>\n",
       "      <td>30.24</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>05-02-11</td>\n",
       "      <td>14656174</td>\n",
       "      <td>14451851</td>\n",
       "      <td>R004</td>\n",
       "      <td>0</td>\n",
       "      <td>40.691320</td>\n",
       "      <td>-73.867135</td>\n",
       "      <td>0</td>\n",
       "      <td>30.32</td>\n",
       "      <td>0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>05-03-11</td>\n",
       "      <td>14660126</td>\n",
       "      <td>14454734</td>\n",
       "      <td>R004</td>\n",
       "      <td>0</td>\n",
       "      <td>40.691320</td>\n",
       "      <td>-73.867135</td>\n",
       "      <td>0</td>\n",
       "      <td>30.14</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>05-04-11</td>\n",
       "      <td>14664247</td>\n",
       "      <td>14457780</td>\n",
       "      <td>R004</td>\n",
       "      <td>0</td>\n",
       "      <td>40.691320</td>\n",
       "      <td>-73.867135</td>\n",
       "      <td>0</td>\n",
       "      <td>29.98</td>\n",
       "      <td>0</td>\n",
       "      <td>57.2</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>05-05-11</td>\n",
       "      <td>14668301</td>\n",
       "      <td>14460818</td>\n",
       "      <td>R004</td>\n",
       "      <td>0</td>\n",
       "      <td>40.691320</td>\n",
       "      <td>-73.867135</td>\n",
       "      <td>0</td>\n",
       "      <td>30.01</td>\n",
       "      <td>0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DATEn  ENTRIESn    EXITSn  UNIT  hour   latitude  longitude  fog  \\\n",
       "0  05-01-11   4388333   2911002  R003     0  40.689945 -73.872564    0   \n",
       "1  05-02-11   4388348   2911036  R003     0  40.689945 -73.872564    0   \n",
       "2  05-03-11   4389885   2912127  R003     0  40.689945 -73.872564    0   \n",
       "3  05-04-11   4391507   2913223  R003     0  40.689945 -73.872564    0   \n",
       "4  05-05-11   4393043   2914284  R003     0  40.689945 -73.872564    0   \n",
       "5  05-01-11  14656120  14451774  R004     0  40.691320 -73.867135    0   \n",
       "6  05-02-11  14656174  14451851  R004     0  40.691320 -73.867135    0   \n",
       "7  05-03-11  14660126  14454734  R004     0  40.691320 -73.867135    0   \n",
       "8  05-04-11  14664247  14457780  R004     0  40.691320 -73.867135    0   \n",
       "9  05-05-11  14668301  14460818  R004     0  40.691320 -73.867135    0   \n",
       "\n",
       "   pressurei  rain  tempi  wspdi  \n",
       "0      30.24     0   52.0    8.1  \n",
       "1      30.32     0   48.9    6.9  \n",
       "2      30.14     0   54.0    3.5  \n",
       "3      29.98     0   57.2   15.0  \n",
       "4      30.01     0   48.9   15.0  \n",
       "5      30.24     0   52.0    8.1  \n",
       "6      30.32     0   48.9    6.9  \n",
       "7      30.14     0   54.0    3.5  \n",
       "8      29.98     0   57.2   15.0  \n",
       "9      30.01     0   48.9   15.0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "subway_df = pd.DataFrame({\n",
    "    'UNIT': ['R003', 'R003', 'R003', 'R003', 'R003', 'R004', 'R004', 'R004',\n",
    "             'R004', 'R004'],\n",
    "    'DATEn': ['05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11',\n",
    "              '05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11'],\n",
    "    'hour': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'ENTRIESn': [ 4388333,  4388348,  4389885,  4391507,  4393043, 14656120,\n",
    "                 14656174, 14660126, 14664247, 14668301],\n",
    "    'EXITSn': [ 2911002,  2911036,  2912127,  2913223,  2914284, 14451774,\n",
    "               14451851, 14454734, 14457780, 14460818],\n",
    "    'latitude': [ 40.689945,  40.689945,  40.689945,  40.689945,  40.689945,\n",
    "                  40.69132 ,  40.69132 ,  40.69132 ,  40.69132 ,  40.69132 ],\n",
    "    'longitude': [-73.872564, -73.872564, -73.872564, -73.872564, -73.872564,\n",
    "                  -73.867135, -73.867135, -73.867135, -73.867135, -73.867135]\n",
    "})\n",
    "\n",
    "weather_df = pd.DataFrame({\n",
    "    'DATEn': ['05-01-11', '05-01-11', '05-02-11', '05-02-11', '05-03-11',\n",
    "              '05-03-11', '05-04-11', '05-04-11', '05-05-11', '05-05-11'],\n",
    "    'hour': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'latitude': [ 40.689945,  40.69132 ,  40.689945,  40.69132 ,  40.689945,\n",
    "                  40.69132 ,  40.689945,  40.69132 ,  40.689945,  40.69132 ],\n",
    "    'longitude': [-73.872564, -73.867135, -73.872564, -73.867135, -73.872564,\n",
    "                  -73.867135, -73.872564, -73.867135, -73.872564, -73.867135],\n",
    "    'pressurei': [ 30.24,  30.24,  30.32,  30.32,  30.14,  30.14,  29.98,  29.98,\n",
    "                   30.01,  30.01],\n",
    "    'fog': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'rain': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'tempi': [ 52. ,  52. ,  48.9,  48.9,  54. ,  54. ,  57.2,  57.2,  48.9,  48.9],\n",
    "    'wspdi': [  8.1,   8.1,   6.9,   6.9,   3.5,   3.5,  15. ,  15. ,  15. ,  15. ]\n",
    "})\n",
    "\n",
    "def combine_dfs(subway_df, weather_df):\n",
    "    '''\n",
    "    Fill in this function to take 2 DataFrames, one with subway data and one with weather data,\n",
    "    and return a single dataframe with one row for each date, hour, and location. Only include\n",
    "    times and locations that have both subway data and weather data available.\n",
    "    '''\n",
    "    \n",
    "    unico =  subway_df.merge(weather_df, how='inner', left_on = ['DATEn', 'hour','latitude', 'longitude'], right_on = ['DATEn','hour','latitude','longitude'])\n",
    "    \n",
    "    return unico\n",
    "\n",
    "combine_dfs(subway_df, weather_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting for DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      above_three  value\n",
      "even                    \n",
      "False       False      1\n",
      "True        False      2\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'even'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-e61e4515bbfb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mfirst_even\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexample_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'even'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mfirst_even\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[1;32mprint\u001b[0m \u001b[0mfirst_even\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'even'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Causes an error. 'even' is no longer a column in the DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1995\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1996\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1997\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1999\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2002\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2003\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2004\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1348\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3289\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3290\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3291\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3292\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\pandas\\indexes\\base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   1945\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1946\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1947\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1949\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4154)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4018)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12368)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12322)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'even'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "\n",
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# groupby() without as_index\n",
    "if True:\n",
    "    first_even = example_df.groupby('even').first()\n",
    "    print first_even\n",
    "    print first_even['even'] # Causes an error. 'even' is no longer a column in the DataFrame\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    even above_three  value\n",
      "0  False       False      1\n",
      "1   True       False      2\n",
      "a    False\n",
      "b    False\n",
      "c     True\n",
      "d     True\n",
      "e    False\n",
      "f     True\n",
      "g     True\n",
      "Name: even, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "# groupby() with as_index=False\n",
    "if True:\n",
    "    print example_df.groupby('even', as_index=False).first()\n",
    "    print example_df['even'] # Now 'even' is still a column in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-2d01d75d2d9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mscaled_entries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgrouped_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ENTRIESn_hourly'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mgrouped_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ENTRIESn_hourly'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mgrouped_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\pandas\\core\\ops.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(left, right, name, na_op)\u001b[0m\n\u001b[0;32m    649\u001b[0m                 \u001b[0mlvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m             return left._constructor(wrap_results(na_op(lvalues, rvalues)),\n\u001b[0m\u001b[0;32m    652\u001b[0m                                      \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m                                      dtype=dtype)\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\pandas\\core\\ops.pyc\u001b[0m in \u001b[0;36mna_op\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    580\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m             result = expressions.evaluate(op, str_rep, x, y,\n\u001b[1;32m--> 582\u001b[1;33m                                           raise_on_error=True, **eval_kwargs)\n\u001b[0m\u001b[0;32m    583\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\pandas\\computation\\expressions.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(op, op_str, a, b, raise_on_error, use_numexpr, **eval_kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         return _evaluate(op, op_str, a, b, raise_on_error=raise_on_error,\n\u001b[1;32m--> 209\u001b[1;33m                          **eval_kwargs)\n\u001b[0m\u001b[0;32m    210\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_on_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\pandas\\computation\\expressions.pyc\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[1;34m(op, op_str, a, b, raise_on_error, truediv, reversed, **eval_kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\pandas\\computation\\expressions.pyc\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b, raise_on_error, **eval_kwargs)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_TEST_MODE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0m_store_test_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\pandas\\core\\ops.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m     85\u001b[0m         rsub=arith_method(lambda x, y: y - x, names('rsub'), op('-'),\n\u001b[0;32m     86\u001b[0m                           default_axis=default_axis, reversed=True),\n\u001b[1;32m---> 87\u001b[1;33m         rtruediv=arith_method(lambda x, y: operator.truediv(y, x),\n\u001b[0m\u001b[0;32m     88\u001b[0m                               \u001b[0mnames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rtruediv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruediv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                               \u001b[0mfill_zeros\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_axis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "#scaled_entries = (grouped_data['ENTRIESn_hourly']/grouped_data['ENTRIESn_hourly'].std())\n",
    "grouped_data.plot.hist(alpha=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       0.0\n",
       "4       0.0\n",
       "16     83.0\n",
       "17     24.0\n",
       "18    532.0\n",
       "19    454.0\n",
       "20    247.0\n",
       "Name: ENTRIESn_hourly, dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "grouped_data = subway_df.groupby('rain')\n",
    "    \n",
    "\n",
    "grouped_data.head()['ENTRIESn_hourly']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
